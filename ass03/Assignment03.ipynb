{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 3\n",
    "_Jiajie Lu_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the equipment location example; its text is repeated for convenience. A service man moves between 4 sites, with site 1 denoting home oﬃce, and 2, 3, and 4 denoting remote sites. Work at sites 2,3, and 4 requires the use of an equipment trailer. The cost of relocating the equipment trailer between the sites is $d(j,k) = 300$ for $k\\ne j$. The cost $c(k,j)$ of using the trailer is $100$ if the work is at site $k>1$ and trailer is at site $j\\ne k$ with $j > 1$; $50$ if $j = k$ and $j>1$, and $200$ if the work is at $k>1$ and the trailer is at $j=1$ (home oﬃce). \n",
    "$$\n",
    "c(k,j)=\\left\\{\n",
    "\\begin{aligned}\n",
    "100 && k>1,j\\ne k\\\\\n",
    "50 && k>1,j= k\\\\\n",
    "200 && k>1,j=1\n",
    "\\end{aligned}\n",
    "\\right.\n",
    "$$\n",
    "If the service man is at the home oﬃce, no work is done and cost is zero. At any time, the service man knows their location, observes the location of the next job (or 1 if no job is to be done) and decides whether and where to move the trailer. The transition matrix between job locations is\n",
    "$$\n",
    "p=\\begin{bmatrix}\n",
    "0.1 & 0.3 & 0.3 & 0.3\\\\ \n",
    "0.0 & 0.5 & 0.5 & 0.0\\\\ \n",
    "0.0 & 0.0 & 0.8 & 0.2\\\\ \n",
    "0.4 & 0.0 & 0.0 & 0.6\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, if the current location (job) is 2, the probability that the next job is at 3 is 0.5. Assume the discount factor of 0.95."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a)  Formulate a Markov decision problem to help the repairment decide on the movement of the trailer: deﬁne the state and control space and write the dynamic programming equations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">* State Space :\n",
    "$$\\mathcal{X}=\\{x_t=(j_t,k_t)\\in\\{1,2,3,4\\}\\times\\{1,2,3,4\\}\\}$$ \n",
    "where $j_t$ is current trailer position and $k_t$ is current job position.\n",
    "* Control Space : $$\\mathcal{U}=\\{1,2,3,4\\}$$ is the next trailer position.\n",
    "* Transition kernel:\n",
    "$$\n",
    "P[(j_{t+1},k_{t+1})|j_t,k_t,u_t]=\\left\\{\n",
    "\\begin{aligned}\n",
    "p_{k_t,k_{t+1}} && j_{t+1}=u_t\\\\\n",
    "0 && \\text{otherwise}\n",
    "\\end{aligned}\n",
    "\\right.\n",
    "$$\n",
    "* Step-wise Cost function conditioned with control (j-location of the equipment; k-location of the next job):\n",
    "$$\n",
    "c(j,k,u)=\\left\\{\n",
    "\\begin{aligned}\n",
    "0 && u=j, k=1\\\\\n",
    "50 && u=j=k>1\\\\\n",
    "100 && u=j, k\\ne j, j\\ne1,k>1\\\\\n",
    "200 && u=j=1, k>1, \\\\\n",
    "300 && u\\ne j, k=1\\\\\n",
    "300+50 && u\\ne j, u= k, k>1\\\\ \n",
    "300+100 && u\\ne j, u\\ne k,u\\ne1, k>1\\\\\n",
    "300+200 && u\\ne j, u=1, k>1\n",
    "\\end{aligned}\n",
    "\\right.\n",
    "$$\n",
    "* Dynamic programming equation\n",
    "$$\n",
    "v(j,k)=\\min_{u\\in\\{1,2,3,4\\}}\\{c(j,k,u)+0.95\\sum_{l=1}^{4}v(u,l)p_{kl}\\}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Transition Probability Matrix\n",
    "# For convenience we set up the 5x5 \n",
    "# so that ew can obtain P[j,k] = p_{jk}\n",
    "P = np.array([\n",
    "    [.0, .0, .0, .0, .0],\n",
    "    [.0, .1, .3, .3, .3],\n",
    "    [.0, .0, .5, .5, .0],\n",
    "    [.0, .0, .0, .8, .2],\n",
    "    [.0, .4, .0, .0, .6]\n",
    "])\n",
    "\n",
    "# control space\n",
    "U = np.array([1,2,3,4])\n",
    "\n",
    "# step-wise cost function\n",
    "# c[j,k,u]\n",
    "# j-location of equipment,\n",
    "# k-location of next job,\n",
    "# u-control\n",
    "C = np.zeros((5,5,5))\n",
    "\n",
    "# discounted factor\n",
    "alpha = 0.95\n",
    "\n",
    "# function to get value\n",
    "def get_value(j, k, u):\n",
    "    if u == j:\n",
    "        if k == 1: return 0\n",
    "        if k == j: return 50\n",
    "        if j == 1: return 200\n",
    "        \n",
    "        return 100\n",
    "    else:\n",
    "        if k == 1: return 300\n",
    "        if u == k: return 350\n",
    "        if u == 1: return 500\n",
    "        \n",
    "        return 400\n",
    "\n",
    "# update cost function\n",
    "for i in U:\n",
    "    for j in U:\n",
    "        for u in U:\n",
    "            C[i,j,u] = get_value(i, j, u)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b)  Solve these equations by the value iteration method (starting from 0) and calculate lower and upper bound at each step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With 290 iterations:\n",
      "We got the optimal v star\n",
      "[[1497.76357116 1618.05362423 1546.26984154 1591.73286596]\n",
      " [1428.21779544 1494.24410042 1546.26984154 1494.70404711]\n",
      " [1220.43021183 1318.05362423 1246.26984154 1311.07781043]\n",
      " [1330.1188323  1492.68947665 1439.28841927 1291.73286596]]\n",
      "We got the optimal policy\n",
      "[[1. 3. 3. 4.]\n",
      " [2. 2. 3. 2.]\n",
      " [3. 3. 3. 3.]\n",
      " [4. 4. 4. 4.]]\n",
      "With upper bound\n",
      "[[1497.76404934 1618.05410241 1546.27031972 1591.73334414]\n",
      " [1428.21827362 1494.2445786  1546.27031972 1494.70452528]\n",
      " [1220.43069001 1318.05410241 1246.27031972 1311.0782886 ]\n",
      " [1330.11931047 1492.68995483 1439.28889744 1291.73334414]]\n",
      "And lower bound\n",
      "[[1497.76357116 1618.05362423 1546.26984154 1591.73286596]\n",
      " [1428.21779544 1494.24410042 1546.26984154 1494.70404711]\n",
      " [1220.43021183 1318.05362423 1246.26984154 1311.07781043]\n",
      " [1330.1188323  1492.68947665 1439.28841927 1291.73286596]]\n"
     ]
    }
   ],
   "source": [
    "# Value Iteration\n",
    "def value_iteration(T, max_iter=1000, tol=0.0001):\n",
    "    # TxT is the length of state space\n",
    "    # initial value function\n",
    "    v = np.zeros((T+1, T+1))\n",
    "    v_old = np.zeros((T+1, T+1)) + 10000\n",
    "    # inital policy path\n",
    "    p = np.zeros((T+1, T+1))\n",
    "    # current iteration\n",
    "    current_step = 0\n",
    "    \n",
    "    # value iteration method\n",
    "    while (np.linalg.norm(v - v_old) > tol) and (current_step < max_iter):\n",
    "        v_old = v.copy()\n",
    "        current_step += 1\n",
    "        \n",
    "        for j in U:\n",
    "            for k in U:\n",
    "                tmp = np.array([C[j, k, u] + 0.95*np.sum([P[k, l]*v_old[u, l] for l in U]) for u in U])\n",
    "                v[j, k] = np.min(tmp)\n",
    "                p[j, k] = np.argmin(tmp) + 1\n",
    "                \n",
    "        upper, lower = np.max(v - v_old), np.min(v - v_old)\n",
    "        \n",
    "    return v[1:, 1:], p[1:, 1:], upper, lower, current_step \n",
    "    \n",
    "\n",
    "v, p, upper, lower, iters = value_iteration(4)\n",
    "print(f\"With {iters} iterations:\")\n",
    "print(\"We got the optimal v star\")\n",
    "print(v)\n",
    "print(\"We got the optimal policy\")\n",
    "print(p)\n",
    "print(\"With upper bound\")\n",
    "print(v + alpha/(1-alpha)*upper)\n",
    "print(\"And lower bound\")\n",
    "print(v + alpha/(1-alpha)*lower)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c)  Solve the problem by the policy iteration method starting from “do not move trailer from base” at each state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With 4 iterations:\n",
      "We got the optimal v star\n",
      "[[1497.76402404 1618.05406446 1546.27028177 1591.73334414]\n",
      " [1428.21823567 1494.24454065 1546.27028177 1494.70448733]\n",
      " [1220.43065206 1318.05406446 1246.27028177 1311.07825065]\n",
      " [1330.11931047 1492.68995483 1439.28889744 1291.73334414]]\n",
      "We got the optimal policy\n",
      "[[1 3 3 4]\n",
      " [2 2 3 2]\n",
      " [3 3 3 3]\n",
      " [4 4 4 4]]\n"
     ]
    }
   ],
   "source": [
    "# Policy iteration\n",
    "def policy_iteration(T, max_iter=1000, tol=0.001):\n",
    "    # inital policy matrix\n",
    "    p = np.array([0 for _ in range(T**2)])\n",
    "    p_old = np.array([0 for _ in range(T**2)]) + 10\n",
    "    # current step\n",
    "    current_step = 0\n",
    "    \n",
    "    # policy iteration method\n",
    "    while (np.linalg.norm(p - p_old) > tol) and (current_step < max_iter):\n",
    "        p_old = p.copy()\n",
    "        current_step += 1\n",
    "        \n",
    "        # init coef\n",
    "        A = np.zeros((T**2, T**2))\n",
    "        # init bias\n",
    "        b = np.array([0 for _ in range(T**2)])\n",
    "        # set up coef and bias\n",
    "        for row, j in enumerate(U):\n",
    "            for col, k in enumerate(U):\n",
    "                idx = row*T + col\n",
    "                b[idx] = -C[j, k, p[idx]]\n",
    "                policy = p_old[idx]\n",
    "                \n",
    "                for l in range(T):\n",
    "                    A[idx, (p[idx]-1)*T+l] += alpha*P[k, l+1]\n",
    "        \n",
    "        # set up A    \n",
    "        A = A - np.eye(T**2)\n",
    "        # solve the linear equation Ax=b\n",
    "        v = np.linalg.solve(A, b)\n",
    "        # update policy\n",
    "        for row, j in enumerate(U):\n",
    "            for col, k in enumerate(U): \n",
    "                tmp = np.array([C[j, k, u] + 0.95*np.sum([P[k, l]*v[(u-1)*T+l-1] for l in U]) for u in U])\n",
    "                p[row*T + col] = np.argmin(tmp) + 1\n",
    "                \n",
    "    return v.reshape((T,T)), p.reshape((T,T)), current_step, b\n",
    "\n",
    "v, p, iters, b = policy_iteration(4)\n",
    "print(f\"With {iters} iterations:\")\n",
    "print(\"We got the optimal v star\")\n",
    "print(v)\n",
    "print(\"We got the optimal policy\")\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d) Solve the problem by linear programming."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{aligned}\n",
    "\\max & \\sum_{j,k} v(j, k)\\\\\n",
    "\\text{s.t.} & v(j, k)\\le c(j,k,u)+\\alpha \\sum_{l\\in\\mathcal{X}}\\left[ v(u, l)p_{kl} \\right],\\quad (j,k)\\in\\mathcal{X}\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V star by dynamic programming:\n",
      "[[1497.76402382 1618.05406424 1546.27028155 1591.73334389]\n",
      " [1428.21823543 1494.24454041 1546.27028157 1494.70448709]\n",
      " [1220.4306519  1318.05406429 1246.27028161 1311.07825049]\n",
      " [1330.1193103  1492.68995463 1439.28889726 1291.73334397]]\n"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import linprog\n",
    "\n",
    "# linear programming\n",
    "def linear_programming(T):\n",
    "    # min c^Tv\n",
    "    # Av <= b\n",
    "    # parameter array c\n",
    "    c = np.array([-1.0 for _ in range(T**2)])\n",
    "    # coef matrix\n",
    "    A = np.zeros((T**2*len(U), T**2))\n",
    "    # const \n",
    "    b = np.array([0.0 for _ in range(T**2*len(U))])\n",
    "    \n",
    "    for row, j in enumerate(U):\n",
    "        for col, k in enumerate(U):\n",
    "            for i, u in enumerate(U):\n",
    "                # current index\n",
    "                r_idx = row*(T**2) + col*T + i\n",
    "                c_idx = row*T + col\n",
    "                # set entry value\n",
    "                A[r_idx, c_idx] += 1.0\n",
    "                b[r_idx] = C[j, k, u]\n",
    "                \n",
    "                for l in range(T):\n",
    "                    A[r_idx, i*T+l] -= alpha*P[k, l+1]\n",
    "                    \n",
    "    # solve linear programming\n",
    "    v = linprog(c, A, b)\n",
    "    \n",
    "    return v['x'].reshape(T,T)\n",
    "\n",
    "v = linear_programming(4)\n",
    "print(\"V star by dynamic programming:\")\n",
    "print(v)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
